{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【第1回_Beginner限定コンペ】銀行の顧客ターゲティング\n",
    "\n",
    "顧客の属性情報などから定期預金キャンペーンの反応率を予測しよう。\n",
    "\n",
    "https://signate.jp/competitions/292\n",
    "\n",
    "Deep Table編"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "\n",
    "from deeptables.models.deeptable import DeepTable, ModelConfig\n",
    "from deeptables.models.deepnets import DeepFM, xDeepFM, DCN, PNN, WideDeep, AutoInt, AFM, FGCNN\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import optuna\n",
    "\n",
    "# Optuna 並列処理 マルチGPU\n",
    "# https://github.com/optuna/optuna/issues/1365\n",
    "#from multiprocessing import Manager\n",
    "#from joblib import parallel_backend\n",
    "\n",
    "#from dask.distributed import Client, wait\n",
    "#from dask_cuda import LocalCUDACluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# マルチGPUチェック\n",
    "#cluster = LocalCUDACluster()\n",
    "#client = Client(cluster)\n",
    "\n",
    "#n_gpus = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_stats(df):\n",
    "    stats = []\n",
    "    for col in df.columns:\n",
    "        stats.append((col,\n",
    "                      df[col].nunique(),\n",
    "                      df[col].value_counts().index[0],\n",
    "                      df[col].value_counts().values[0],\n",
    "                      df[col].isnull().sum() * 100 / df.shape[0],\n",
    "                      df[col].value_counts(normalize=True, dropna=False).values[0] * 100,\n",
    "                      df[col].dtype))\n",
    "    return pd.DataFrame(stats, columns=['カラム名', 'カラムごとのユニーク値数', '最も出現頻度の高い値', '最も出現頻度の高い値の出現回数', '欠損損値の割合', '最も多いカテゴリの割合', 'Type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ読み込み・前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "submit_df = pd.read_csv('submit_sample.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo Labeling\n",
    "#test_p1_df = pd.read_csv('test_p1.csv')\n",
    "\n",
    "#train_df = pd.concat([train_df, test_p1_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [train_df, test_df]\n",
    "\n",
    "for df in df_list:\n",
    "    df['job'] = df['job'].map({'unknown': 1, 'technician': 2, 'blue-collar': 3, 'services': 4, 'entrepreneur': 5, 'admin.': 6, 'management': 7, 'housemaid': 8, 'self-employed': 9, 'unemployed': 10, 'retired': 11, 'student': 12})\n",
    "    \n",
    "    df['marital'] = df['marital'].map({'married': 2, 'divorced':1, 'single': 0})\n",
    "    #df.drop(['marital'], axis=1, inplace=True)\n",
    "\n",
    "    df['education'] = df['education'].map({'tertiary': 3, 'secondary': 2, 'primary': 1, 'unknown': 0})\n",
    "    #df.drop(['education'], axis=1, inplace=True)\n",
    "\n",
    "    #df['default'] = df['default'].map({'yes': 1, 'no': 0})\n",
    "    df.drop(['default'], axis=1, inplace=True)\n",
    "\n",
    "    df['housing'] = df['housing'].map({'yes': 1, 'no': 0})\n",
    "    #df.drop(['housing'], axis=1, inplace=True)\n",
    "    \n",
    "    df['loan'] = df['loan'].map({'yes': 1, 'no': 0})\n",
    "    #df.drop(['loan'], axis=1, inplace=True)\n",
    "\n",
    "    df['contact'] = df['contact'].map({'telephone': 2, 'cellular': 1, 'unknown': 0})\n",
    "    #df.drop(['contact'], axis=1, inplace=True)\n",
    "\n",
    "    df['poutcome'] = df['poutcome'].map({'success': 3, 'unknown': 2, 'failure': 1, 'other': 0})\n",
    "    #df['p_label_mean'] = np.log(df['poutcome'].map(p_label_mean))\n",
    "    #df.drop(['poutcome'], axis=1, inplace=True)\n",
    "    \n",
    "    df['month'] = df['month'].map({'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6, 'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12})\n",
    "    #df.drop(['day', 'month'], axis=1, inplace=True)\n",
    "    \n",
    "    # Feb 30 とかあって、正確には変換できない\n",
    "    # → データの Feb 30 を Mar 1 に変換した(他にも、 2/31, 6/31, 11/31)\n",
    "    #df['dayofyear'] = df['month'] * 31 + df['day']\n",
    "    df['datetime'] = pd.to_datetime('2012/' + df['month'].astype(str).str.pad(2,fillchar='0') + '/' + df['day'].astype(str).str.pad(2,fillchar='0'), format='%Y/%m/%d')\n",
    "    df['dayofyear'] = df['datetime'].dt.dayofyear\n",
    "    #df['dayofweek'] = df['datetime'].dt.dayofweek\n",
    "    df.drop(['datetime'], axis=1, inplace=True)\n",
    "\n",
    "    df['duration'] = np.log(df['duration'] + 1)\n",
    "\n",
    "    #df['bpp'] = np.log((df['balance'] - df['balance'].min()) / (df['pdays'] + 2) + 1)\n",
    "    #df['cdp'] = (df['campaign'] - df['previous']) * df['duration']\n",
    "    \n",
    "    df.drop(['pdays'], axis=1, inplace=True)\n",
    "    df.drop(['balance'], axis=1, inplace=True)\n",
    "    \n",
    "    df.drop(['id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df.pop('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 2.89 MB\n",
      "Memory usage after optimization is: 0.41 MB\n",
      "Decreased by 85.7%\n",
      "Memory usage of dataframe is 1.93 MB\n",
      "Memory usage after optimization is: 0.28 MB\n",
      "Decreased by 85.7%\n"
     ]
    }
   ],
   "source": [
    "train_df = reduce_mem_usage(train_df)\n",
    "test_df = reduce_mem_usage(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27100 entries, 0 to 27099\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   age        27100 non-null  int8   \n",
      " 1   job        27100 non-null  int8   \n",
      " 2   marital    27100 non-null  int8   \n",
      " 3   education  27100 non-null  int8   \n",
      " 4   housing    27100 non-null  int8   \n",
      " 5   loan       27100 non-null  int8   \n",
      " 6   contact    27100 non-null  int8   \n",
      " 7   day        27100 non-null  int8   \n",
      " 8   month      27100 non-null  int8   \n",
      " 9   duration   27100 non-null  float16\n",
      " 10  campaign   27100 non-null  int8   \n",
      " 11  previous   27100 non-null  int8   \n",
      " 12  poutcome   27100 non-null  int8   \n",
      " 13  dayofyear  27100 non-null  int16  \n",
      "dtypes: float16(1), int16(1), int8(12)\n",
      "memory usage: 423.6 KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>dayofyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27100.000000</td>\n",
       "      <td>27100.000000</td>\n",
       "      <td>27100.000000</td>\n",
       "      <td>27100.000000</td>\n",
       "      <td>27100.000000</td>\n",
       "      <td>27100.000000</td>\n",
       "      <td>27100.000000</td>\n",
       "      <td>27100.000000</td>\n",
       "      <td>27100.000000</td>\n",
       "      <td>2.710000e+04</td>\n",
       "      <td>27100.000000</td>\n",
       "      <td>27100.000000</td>\n",
       "      <td>27100.000000</td>\n",
       "      <td>27100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>36.073284</td>\n",
       "      <td>5.152509</td>\n",
       "      <td>1.386162</td>\n",
       "      <td>2.046125</td>\n",
       "      <td>0.583727</td>\n",
       "      <td>0.127269</td>\n",
       "      <td>0.788007</td>\n",
       "      <td>16.700443</td>\n",
       "      <td>6.003542</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.775830</td>\n",
       "      <td>0.085720</td>\n",
       "      <td>1.855683</td>\n",
       "      <td>168.623579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.816417</td>\n",
       "      <td>2.669990</td>\n",
       "      <td>0.872384</td>\n",
       "      <td>0.727044</td>\n",
       "      <td>0.492949</td>\n",
       "      <td>0.333281</td>\n",
       "      <td>0.498535</td>\n",
       "      <td>8.576252</td>\n",
       "      <td>2.135158</td>\n",
       "      <td>7.719727e-01</td>\n",
       "      <td>0.950045</td>\n",
       "      <td>0.365889</td>\n",
       "      <td>0.467181</td>\n",
       "      <td>65.155774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.804688e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>136.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.070312e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>148.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.847656e+00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>199.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.031250e+00</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>336.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age           job       marital     education       housing  \\\n",
       "count  27100.000000  27100.000000  27100.000000  27100.000000  27100.000000   \n",
       "mean      36.073284      5.152509      1.386162      2.046125      0.583727   \n",
       "std        7.816417      2.669990      0.872384      0.727044      0.492949   \n",
       "min       22.000000      2.000000      0.000000      0.000000      0.000000   \n",
       "25%       31.000000      3.000000      0.000000      2.000000      0.000000   \n",
       "50%       33.000000      5.000000      2.000000      2.000000      1.000000   \n",
       "75%       37.000000      7.000000      2.000000      2.000000      1.000000   \n",
       "max       90.000000     12.000000      2.000000      3.000000      1.000000   \n",
       "\n",
       "               loan       contact           day         month      duration  \\\n",
       "count  27100.000000  27100.000000  27100.000000  27100.000000  2.710000e+04   \n",
       "mean       0.127269      0.788007     16.700443      6.003542           inf   \n",
       "std        0.333281      0.498535      8.576252      2.135158  7.719727e-01   \n",
       "min        0.000000      0.000000      1.000000      1.000000  0.000000e+00   \n",
       "25%        0.000000      0.000000      8.000000      5.000000  4.804688e+00   \n",
       "50%        0.000000      1.000000     17.000000      5.000000  5.070312e+00   \n",
       "75%        0.000000      1.000000     26.000000      7.000000  5.847656e+00   \n",
       "max        1.000000      2.000000     31.000000     12.000000  8.031250e+00   \n",
       "\n",
       "           campaign      previous      poutcome     dayofyear  \n",
       "count  27100.000000  27100.000000  27100.000000  27100.000000  \n",
       "mean       1.775830      0.085720      1.855683    168.623579  \n",
       "std        0.950045      0.365889      0.467181     65.155774  \n",
       "min        1.000000      0.000000      0.000000      3.000000  \n",
       "25%        1.000000      0.000000      2.000000    136.000000  \n",
       "50%        1.000000      0.000000      2.000000    148.000000  \n",
       "75%        2.000000      0.000000      2.000000    199.000000  \n",
       "max        5.000000      3.000000      3.000000    336.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>カラム名</th>\n",
       "      <th>カラムごとのユニーク値数</th>\n",
       "      <th>最も出現頻度の高い値</th>\n",
       "      <th>最も出現頻度の高い値の出現回数</th>\n",
       "      <th>欠損損値の割合</th>\n",
       "      <th>最も多いカテゴリの割合</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>42</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>4464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.472325</td>\n",
       "      <td>int8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>job</td>\n",
       "      <td>11</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.981550</td>\n",
       "      <td>int8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marital</td>\n",
       "      <td>3</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>17565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.815498</td>\n",
       "      <td>int8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>education</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.874539</td>\n",
       "      <td>int8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>housing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.372694</td>\n",
       "      <td>int8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>loan</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.273063</td>\n",
       "      <td>int8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>contact</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.653137</td>\n",
       "      <td>int8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>day</td>\n",
       "      <td>30</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>4129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.236162</td>\n",
       "      <td>int8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>month</td>\n",
       "      <td>12</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.446494</td>\n",
       "      <td>int8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>duration</td>\n",
       "      <td>140</td>\n",
       "      <td>5.070312</td>\n",
       "      <td>5759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.250923</td>\n",
       "      <td>float16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>campaign</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.808118</td>\n",
       "      <td>int8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>previous</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25461</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.952030</td>\n",
       "      <td>int8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>poutcome</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.236162</td>\n",
       "      <td>int8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dayofyear</td>\n",
       "      <td>244</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>4095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.110701</td>\n",
       "      <td>int16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         カラム名  カラムごとのユニーク値数  最も出現頻度の高い値  最も出現頻度の高い値の出現回数  欠損損値の割合  \\\n",
       "0         age            42   31.000000             4464      0.0   \n",
       "1         job            11    3.000000             5957      0.0   \n",
       "2     marital             3    2.000000            17565      0.0   \n",
       "3   education             4    2.000000            15955      0.0   \n",
       "4     housing             2    1.000000            15819      0.0   \n",
       "5        loan             2    0.000000            23651      0.0   \n",
       "6     contact             3    1.000000            19147      0.0   \n",
       "7         day            30   27.000000             4129      0.0   \n",
       "8       month            12    5.000000            11232      0.0   \n",
       "9    duration           140    5.070312             5759      0.0   \n",
       "10   campaign             5    1.000000            13769      0.0   \n",
       "11   previous             4    0.000000            25461      0.0   \n",
       "12   poutcome             4    2.000000            23099      0.0   \n",
       "13  dayofyear           244  148.000000             4095      0.0   \n",
       "\n",
       "    最も多いカテゴリの割合     Type  \n",
       "0     16.472325     int8  \n",
       "1     21.981550     int8  \n",
       "2     64.815498     int8  \n",
       "3     58.874539     int8  \n",
       "4     58.372694     int8  \n",
       "5     87.273063     int8  \n",
       "6     70.653137     int8  \n",
       "7     15.236162     int8  \n",
       "8     41.446494     int8  \n",
       "9     21.250923  float16  \n",
       "10    50.808118     int8  \n",
       "11    93.952030     int8  \n",
       "12    85.236162     int8  \n",
       "13    15.110701    int16  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Objective():\n",
    "    def __init__(self):\n",
    "        self.best_pred = None\n",
    "        self._pred = None\n",
    "\n",
    "    def __call__(self, trial):\n",
    "        nets = trial.suggest_categorical('nets', [DeepFM, xDeepFM, DCN, PNN, WideDeep, AutoInt, AFM, FGCNN])\n",
    "        output_dim = trial.suggest_int('output_dim', 4, 20)\n",
    "        \n",
    "        conf = ModelConfig(\n",
    "            nets=nets, \n",
    "            metrics=['AUC'], \n",
    "            auto_discrete=True,\n",
    "            auto_categorize=True,\n",
    "            cat_exponent=0.5,\n",
    "            monitor_metric='val_auc',\n",
    "            earlystopping_patience=3,\n",
    "            stacking_op='concat',\n",
    "            output_use_bias=True,\n",
    "            fixed_embedding_dim=True,\n",
    "            embeddings_regularizer='l2',\n",
    "            embeddings_output_dim=output_dim,\n",
    "            embedding_dropout=0.,\n",
    "            dnn_params={\n",
    "               'hidden_units':(\n",
    "                   (2**8, 0., True),\n",
    "                   (2**7, 0., True),\n",
    "                   (2**6, 0., True),\n",
    "                   (2**5, 0., True),\n",
    "                   (2**4, 0., True),\n",
    "                   (2**3, 0., True),\n",
    "                   (1, 0., True),\n",
    "                   ), #hidden_units\n",
    "               'dnn_activation':'relu'\n",
    "            },\n",
    "        )\n",
    "        \n",
    "        dt = DeepTable(config = conf)\n",
    "\n",
    "        oof_proba, eval_proba, test_proba = dt.fit_cross_validation(\n",
    "            train_df,\n",
    "            y,\n",
    "            X_eval=None,\n",
    "            X_test=test_df,\n",
    "            num_folds=5,\n",
    "            stratified=False,\n",
    "            random_state=22,\n",
    "            iterators=None, \n",
    "            batch_size=24,\n",
    "            epochs=100,\n",
    "            verbose=0,\n",
    "            callbacks=[],\n",
    "            n_jobs=1,\n",
    "        )\n",
    "        \n",
    "        self._pred = test_proba\n",
    "        \n",
    "        AUC = roc_auc_score(y, oof_proba)\n",
    "        return AUC\n",
    "    \n",
    "    def callback(self, study, trial):\n",
    "        if study.best_trial == trial:\n",
    "            self.best_pred = self._pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'fm_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'cin_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['dcn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['pnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['autoint_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['afm_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['fgcnn_dnn_nets'] which is of type list.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cross validation\n",
      "2 class detected, {0, 1}, so inferred as a [binary classification] task\n",
      "Preparing features cost:0.10191512107849121\n",
      "Imputation cost:0.1154932975769043\n",
      "Categorical encoding cost:0.19885969161987305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretization cost:0.14821481704711914\n",
      "fit_transform cost:0.5807263851165771\n",
      "transform X_test\n",
      "transform_X cost:3.8564205169677734\n",
      "Iterators:KFold(n_splits=5, random_state=22, shuffle=True)\n",
      "Injected a callback [EarlyStopping]. monitor:val_auc, patience:3, mode:max\n",
      "\n",
      "Fold:1\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 230)\n",
      "---------------------------------------------------------\n",
      "nets: ['autoint_nets']\n",
      "---------------------------------------------------------\n",
      "autoint: input_shape (None, 27, 8), output_shape (None, 216)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Fold 1 fitting over.\n",
      "Fold 1 scoring over.\n",
      "Save model to:dt_output/dt_20200830 171915_autoint_nets/autoint_nets-kfold-1.h5.\n",
      "\n",
      "Fold:2\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 230)\n",
      "---------------------------------------------------------\n",
      "nets: ['autoint_nets']\n",
      "---------------------------------------------------------\n",
      "autoint: input_shape (None, 27, 8), output_shape (None, 216)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00005: early stopping\n",
      "Fold 2 fitting over.\n",
      "Fold 2 scoring over.\n",
      "Save model to:dt_output/dt_20200830 171915_autoint_nets/autoint_nets-kfold-2.h5.\n",
      "\n",
      "Fold:3\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 230)\n",
      "---------------------------------------------------------\n",
      "nets: ['autoint_nets']\n",
      "---------------------------------------------------------\n",
      "autoint: input_shape (None, 27, 8), output_shape (None, 216)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Fold 3 fitting over.\n",
      "Fold 3 scoring over.\n",
      "Save model to:dt_output/dt_20200830 171915_autoint_nets/autoint_nets-kfold-3.h5.\n",
      "\n",
      "Fold:4\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 230)\n",
      "---------------------------------------------------------\n",
      "nets: ['autoint_nets']\n",
      "---------------------------------------------------------\n",
      "autoint: input_shape (None, 27, 8), output_shape (None, 216)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Fold 4 fitting over.\n",
      "Fold 4 scoring over.\n",
      "Save model to:dt_output/dt_20200830 171915_autoint_nets/autoint_nets-kfold-4.h5.\n",
      "\n",
      "Fold:5\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 230)\n",
      "---------------------------------------------------------\n",
      "nets: ['autoint_nets']\n",
      "---------------------------------------------------------\n",
      "autoint: input_shape (None, 27, 8), output_shape (None, 216)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Fold 5 fitting over.\n",
      "Fold 5 scoring over.\n",
      "Save model to:dt_output/dt_20200830 171915_autoint_nets/autoint_nets-kfold-5.h5.\n",
      "fit_cross_validation cost:781.4048707485199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-30 17:32:17,071] Trial 0 finished with value: 0.8555407637332586 and parameters: {'nets': ['autoint_nets'], 'output_dim': 8}. Best is trial 0 with value: 0.8555407637332586.\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'fm_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'cin_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['dcn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['pnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['autoint_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['afm_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['fgcnn_dnn_nets'] which is of type list.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cross validation\n",
      "2 class detected, {0, 1}, so inferred as a [binary classification] task\n",
      "Preparing features cost:0.10299897193908691\n",
      "Imputation cost:0.11427474021911621\n",
      "Categorical encoding cost:0.2092888355255127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretization cost:0.14595437049865723\n",
      "fit_transform cost:0.5836241245269775\n",
      "transform X_test\n",
      "transform_X cost:3.8564693927764893\n",
      "Iterators:KFold(n_splits=5, random_state=22, shuffle=True)\n",
      "Injected a callback [EarlyStopping]. monitor:val_auc, patience:3, mode:max\n",
      "\n",
      "Fold:1\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 446)\n",
      "---------------------------------------------------------\n",
      "nets: ['fgcnn_dnn_nets']\n",
      "---------------------------------------------------------\n",
      "fg: input_shape (None, 27, 16), output_shape (None, 109, 16)\n",
      "fgcnn-ipnn: input_shape (None, 109, 16), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Fold 1 fitting over.\n",
      "Fold 1 scoring over.\n",
      "Save model to:dt_output/dt_20200830 173217_fgcnn_dnn_nets/fgcnn_dnn_nets-kfold-1.h5.\n",
      "\n",
      "Fold:2\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 446)\n",
      "---------------------------------------------------------\n",
      "nets: ['fgcnn_dnn_nets']\n",
      "---------------------------------------------------------\n",
      "fg: input_shape (None, 27, 16), output_shape (None, 109, 16)\n",
      "fgcnn-ipnn: input_shape (None, 109, 16), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Fold 2 fitting over.\n",
      "Fold 2 scoring over.\n",
      "Save model to:dt_output/dt_20200830 173217_fgcnn_dnn_nets/fgcnn_dnn_nets-kfold-2.h5.\n",
      "\n",
      "Fold:3\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 446)\n",
      "---------------------------------------------------------\n",
      "nets: ['fgcnn_dnn_nets']\n",
      "---------------------------------------------------------\n",
      "fg: input_shape (None, 27, 16), output_shape (None, 109, 16)\n",
      "fgcnn-ipnn: input_shape (None, 109, 16), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Fold 3 fitting over.\n",
      "Fold 3 scoring over.\n",
      "Save model to:dt_output/dt_20200830 173217_fgcnn_dnn_nets/fgcnn_dnn_nets-kfold-3.h5.\n",
      "\n",
      "Fold:4\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 446)\n",
      "---------------------------------------------------------\n",
      "nets: ['fgcnn_dnn_nets']\n",
      "---------------------------------------------------------\n",
      "fg: input_shape (None, 27, 16), output_shape (None, 109, 16)\n",
      "fgcnn-ipnn: input_shape (None, 109, 16), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "Fold 4 fitting over.\n",
      "Fold 4 scoring over.\n",
      "Save model to:dt_output/dt_20200830 173217_fgcnn_dnn_nets/fgcnn_dnn_nets-kfold-4.h5.\n",
      "\n",
      "Fold:5\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 446)\n",
      "---------------------------------------------------------\n",
      "nets: ['fgcnn_dnn_nets']\n",
      "---------------------------------------------------------\n",
      "fg: input_shape (None, 27, 16), output_shape (None, 109, 16)\n",
      "fgcnn-ipnn: input_shape (None, 109, 16), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Fold 5 fitting over.\n",
      "Fold 5 scoring over.\n",
      "Save model to:dt_output/dt_20200830 173217_fgcnn_dnn_nets/fgcnn_dnn_nets-kfold-5.h5.\n",
      "fit_cross_validation cost:1472.705281496048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-30 17:56:49,799] Trial 1 finished with value: 0.8401137849197918 and parameters: {'nets': ['fgcnn_dnn_nets'], 'output_dim': 16}. Best is trial 0 with value: 0.8555407637332586.\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'fm_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'cin_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['dcn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['pnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['autoint_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['afm_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['fgcnn_dnn_nets'] which is of type list.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cross validation\n",
      "2 class detected, {0, 1}, so inferred as a [binary classification] task\n",
      "Preparing features cost:0.10259294509887695\n",
      "Imputation cost:0.10960721969604492\n",
      "Categorical encoding cost:0.20315217971801758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretization cost:0.14509010314941406\n",
      "fit_transform cost:0.5715346336364746\n",
      "transform X_test\n",
      "transform_X cost:3.8678483963012695\n",
      "Iterators:KFold(n_splits=5, random_state=22, shuffle=True)\n",
      "Injected a callback [EarlyStopping]. monitor:val_auc, patience:3, mode:max\n",
      "\n",
      "Fold:1\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 338)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets', 'linear', 'fm_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 338), output_shape (None, 1)\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "fm: input_shape (None, 27, 12), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Fold 1 fitting over.\n",
      "Fold 1 scoring over.\n",
      "Save model to:dt_output/dt_20200830 175649_dnn_nets_linear_fm_nets/dnn_nets_linear_fm_nets-kfold-1.h5.\n",
      "\n",
      "Fold:2\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 338)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets', 'linear', 'fm_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 338), output_shape (None, 1)\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "fm: input_shape (None, 27, 12), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Fold 2 fitting over.\n",
      "Fold 2 scoring over.\n",
      "Save model to:dt_output/dt_20200830 175649_dnn_nets_linear_fm_nets/dnn_nets_linear_fm_nets-kfold-2.h5.\n",
      "\n",
      "Fold:3\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 338)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets', 'linear', 'fm_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 338), output_shape (None, 1)\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "fm: input_shape (None, 27, 12), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Fold 3 fitting over.\n",
      "Fold 3 scoring over.\n",
      "Save model to:dt_output/dt_20200830 175649_dnn_nets_linear_fm_nets/dnn_nets_linear_fm_nets-kfold-3.h5.\n",
      "\n",
      "Fold:4\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 338)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets', 'linear', 'fm_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 338), output_shape (None, 1)\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "fm: input_shape (None, 27, 12), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Fold 4 fitting over.\n",
      "Fold 4 scoring over.\n",
      "Save model to:dt_output/dt_20200830 175649_dnn_nets_linear_fm_nets/dnn_nets_linear_fm_nets-kfold-4.h5.\n",
      "\n",
      "Fold:5\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 338)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets', 'linear', 'fm_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 338), output_shape (None, 1)\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "fm: input_shape (None, 27, 12), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Fold 5 fitting over.\n",
      "Fold 5 scoring over.\n",
      "Save model to:dt_output/dt_20200830 175649_dnn_nets_linear_fm_nets/dnn_nets_linear_fm_nets-kfold-5.h5.\n",
      "fit_cross_validation cost:1172.487113237381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-30 18:16:22,314] Trial 2 finished with value: 0.8556300300659468 and parameters: {'nets': ['linear', 'fm_nets', 'dnn_nets'], 'output_dim': 12}. Best is trial 2 with value: 0.8556300300659468.\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'fm_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'cin_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['dcn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['pnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['autoint_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['afm_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['fgcnn_dnn_nets'] which is of type list.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cross validation\n",
      "2 class detected, {0, 1}, so inferred as a [binary classification] task\n",
      "Preparing features cost:0.10290336608886719\n",
      "Imputation cost:0.11014342308044434\n",
      "Categorical encoding cost:0.20763087272644043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretization cost:0.14838004112243652\n",
      "fit_transform cost:0.5812852382659912\n",
      "transform X_test\n",
      "transform_X cost:3.8942599296569824\n",
      "Iterators:KFold(n_splits=5, random_state=22, shuffle=True)\n",
      "Injected a callback [EarlyStopping]. monitor:val_auc, patience:3, mode:max\n",
      "\n",
      "Fold:1\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 176)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets', 'linear', 'fm_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 176), output_shape (None, 1)\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "fm: input_shape (None, 27, 6), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Fold 1 fitting over.\n",
      "Fold 1 scoring over.\n",
      "Save model to:dt_output/dt_20200830 181622_dnn_nets_linear_fm_nets/dnn_nets_linear_fm_nets-kfold-1.h5.\n",
      "\n",
      "Fold:2\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 176)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets', 'linear', 'fm_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 176), output_shape (None, 1)\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "fm: input_shape (None, 27, 6), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Fold 2 fitting over.\n",
      "Fold 2 scoring over.\n",
      "Save model to:dt_output/dt_20200830 181622_dnn_nets_linear_fm_nets/dnn_nets_linear_fm_nets-kfold-2.h5.\n",
      "\n",
      "Fold:3\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 176)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets', 'linear', 'fm_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 176), output_shape (None, 1)\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "fm: input_shape (None, 27, 6), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Fold 3 fitting over.\n",
      "Fold 3 scoring over.\n",
      "Save model to:dt_output/dt_20200830 181622_dnn_nets_linear_fm_nets/dnn_nets_linear_fm_nets-kfold-3.h5.\n",
      "\n",
      "Fold:4\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 176)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets', 'linear', 'fm_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 176), output_shape (None, 1)\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "fm: input_shape (None, 27, 6), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Fold 4 fitting over.\n",
      "Fold 4 scoring over.\n",
      "Save model to:dt_output/dt_20200830 181622_dnn_nets_linear_fm_nets/dnn_nets_linear_fm_nets-kfold-4.h5.\n",
      "\n",
      "Fold:5\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 176)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets', 'linear', 'fm_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 176), output_shape (None, 1)\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "fm: input_shape (None, 27, 6), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Fold 5 fitting over.\n",
      "Fold 5 scoring over.\n",
      "Save model to:dt_output/dt_20200830 181622_dnn_nets_linear_fm_nets/dnn_nets_linear_fm_nets-kfold-5.h5.\n",
      "fit_cross_validation cost:689.1519727706909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-30 18:27:51,490] Trial 3 finished with value: 0.8498374863874054 and parameters: {'nets': ['linear', 'fm_nets', 'dnn_nets'], 'output_dim': 6}. Best is trial 2 with value: 0.8556300300659468.\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'fm_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'cin_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['dcn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['pnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['autoint_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['afm_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['fgcnn_dnn_nets'] which is of type list.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cross validation\n",
      "2 class detected, {0, 1}, so inferred as a [binary classification] task\n",
      "Preparing features cost:0.10078740119934082\n",
      "Imputation cost:0.11117219924926758\n",
      "Categorical encoding cost:0.20016074180603027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretization cost:0.1466677188873291\n",
      "fit_transform cost:0.5707015991210938\n",
      "transform X_test\n",
      "transform_X cost:3.884639263153076\n",
      "Iterators:KFold(n_splits=5, random_state=22, shuffle=True)\n",
      "Injected a callback [EarlyStopping]. monitor:val_auc, patience:3, mode:max\n",
      "\n",
      "Fold:1\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 257)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 9), output_shape (None, 1)\n",
      "dnn: input_shape (None, 257), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Fold 1 fitting over.\n",
      "Fold 1 scoring over.\n",
      "Save model to:dt_output/dt_20200830 182751_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-1.h5.\n",
      "\n",
      "Fold:2\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 257)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 9), output_shape (None, 1)\n",
      "dnn: input_shape (None, 257), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00005: early stopping\n",
      "Fold 2 fitting over.\n",
      "Fold 2 scoring over.\n",
      "Save model to:dt_output/dt_20200830 182751_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-2.h5.\n",
      "\n",
      "Fold:3\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 257)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 9), output_shape (None, 1)\n",
      "dnn: input_shape (None, 257), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00005: early stopping\n",
      "Fold 3 fitting over.\n",
      "Fold 3 scoring over.\n",
      "Save model to:dt_output/dt_20200830 182751_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-3.h5.\n",
      "\n",
      "Fold:4\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 257)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 9), output_shape (None, 1)\n",
      "dnn: input_shape (None, 257), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Fold 4 fitting over.\n",
      "Fold 4 scoring over.\n",
      "Save model to:dt_output/dt_20200830 182751_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-4.h5.\n",
      "\n",
      "Fold:5\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 257)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 9), output_shape (None, 1)\n",
      "dnn: input_shape (None, 257), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Fold 5 fitting over.\n",
      "Fold 5 scoring over.\n",
      "Save model to:dt_output/dt_20200830 182751_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-5.h5.\n",
      "fit_cross_validation cost:818.357152223587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-30 18:41:29,872] Trial 4 finished with value: 0.8564291541758227 and parameters: {'nets': ['linear', 'cin_nets', 'dnn_nets'], 'output_dim': 9}. Best is trial 4 with value: 0.8564291541758227.\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'fm_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'cin_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['dcn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['pnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['autoint_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['afm_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['fgcnn_dnn_nets'] which is of type list.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cross validation\n",
      "2 class detected, {0, 1}, so inferred as a [binary classification] task\n",
      "Preparing features cost:0.10169839859008789\n",
      "Imputation cost:0.10850787162780762\n",
      "Categorical encoding cost:0.20424461364746094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretization cost:0.1468360424041748\n",
      "fit_transform cost:0.5726618766784668\n",
      "transform X_test\n",
      "transform_X cost:3.866594076156616\n",
      "Iterators:KFold(n_splits=5, random_state=22, shuffle=True)\n",
      "Injected a callback [EarlyStopping]. monitor:val_auc, patience:3, mode:max\n",
      "\n",
      "Fold:1\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 122)\n",
      "---------------------------------------------------------\n",
      "nets: ['autoint_nets']\n",
      "---------------------------------------------------------\n",
      "autoint: input_shape (None, 27, 4), output_shape (None, 108)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Fold 1 fitting over.\n",
      "Fold 1 scoring over.\n",
      "Save model to:dt_output/dt_20200830 184129_autoint_nets/autoint_nets-kfold-1.h5.\n",
      "\n",
      "Fold:2\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 122)\n",
      "---------------------------------------------------------\n",
      "nets: ['autoint_nets']\n",
      "---------------------------------------------------------\n",
      "autoint: input_shape (None, 27, 4), output_shape (None, 108)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00005: early stopping\n",
      "Fold 2 fitting over.\n",
      "Fold 2 scoring over.\n",
      "Save model to:dt_output/dt_20200830 184129_autoint_nets/autoint_nets-kfold-2.h5.\n",
      "\n",
      "Fold:3\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 122)\n",
      "---------------------------------------------------------\n",
      "nets: ['autoint_nets']\n",
      "---------------------------------------------------------\n",
      "autoint: input_shape (None, 27, 4), output_shape (None, 108)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Fold 3 fitting over.\n",
      "Fold 3 scoring over.\n",
      "Save model to:dt_output/dt_20200830 184129_autoint_nets/autoint_nets-kfold-3.h5.\n",
      "\n",
      "Fold:4\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 122)\n",
      "---------------------------------------------------------\n",
      "nets: ['autoint_nets']\n",
      "---------------------------------------------------------\n",
      "autoint: input_shape (None, 27, 4), output_shape (None, 108)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00005: early stopping\n",
      "Fold 4 fitting over.\n",
      "Fold 4 scoring over.\n",
      "Save model to:dt_output/dt_20200830 184129_autoint_nets/autoint_nets-kfold-4.h5.\n",
      "\n",
      "Fold:5\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 122)\n",
      "---------------------------------------------------------\n",
      "nets: ['autoint_nets']\n",
      "---------------------------------------------------------\n",
      "autoint: input_shape (None, 27, 4), output_shape (None, 108)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Fold 5 fitting over.\n",
      "Fold 5 scoring over.\n",
      "Save model to:dt_output/dt_20200830 184129_autoint_nets/autoint_nets-kfold-5.h5.\n",
      "fit_cross_validation cost:745.2107467651367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-30 18:53:55,108] Trial 5 finished with value: 0.8535378989490713 and parameters: {'nets': ['autoint_nets'], 'output_dim': 4}. Best is trial 4 with value: 0.8564291541758227.\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'fm_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'cin_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['dcn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['pnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['autoint_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['afm_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['fgcnn_dnn_nets'] which is of type list.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cross validation\n",
      "2 class detected, {0, 1}, so inferred as a [binary classification] task\n",
      "Preparing features cost:0.09938335418701172\n",
      "Imputation cost:0.10633087158203125\n",
      "Categorical encoding cost:0.2054884433746338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretization cost:0.1469097137451172\n",
      "fit_transform cost:0.5697569847106934\n",
      "transform X_test\n",
      "transform_X cost:3.8728034496307373\n",
      "Iterators:KFold(n_splits=5, random_state=22, shuffle=True)\n",
      "Injected a callback [EarlyStopping]. monitor:val_auc, patience:3, mode:max\n",
      "\n",
      "Fold:1\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 446)\n",
      "---------------------------------------------------------\n",
      "nets: ['autoint_nets']\n",
      "---------------------------------------------------------\n",
      "autoint: input_shape (None, 27, 16), output_shape (None, 432)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Fold 1 fitting over.\n",
      "Fold 1 scoring over.\n",
      "Save model to:dt_output/dt_20200830 185355_autoint_nets/autoint_nets-kfold-1.h5.\n",
      "\n",
      "Fold:2\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 446)\n",
      "---------------------------------------------------------\n",
      "nets: ['autoint_nets']\n",
      "---------------------------------------------------------\n",
      "autoint: input_shape (None, 27, 16), output_shape (None, 432)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Fold 2 fitting over.\n",
      "Fold 2 scoring over.\n",
      "Save model to:dt_output/dt_20200830 185355_autoint_nets/autoint_nets-kfold-2.h5.\n",
      "\n",
      "Fold:3\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 446)\n",
      "---------------------------------------------------------\n",
      "nets: ['autoint_nets']\n",
      "---------------------------------------------------------\n",
      "autoint: input_shape (None, 27, 16), output_shape (None, 432)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Fold 3 fitting over.\n",
      "Fold 3 scoring over.\n",
      "Save model to:dt_output/dt_20200830 185355_autoint_nets/autoint_nets-kfold-3.h5.\n",
      "\n",
      "Fold:4\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 446)\n",
      "---------------------------------------------------------\n",
      "nets: ['autoint_nets']\n",
      "---------------------------------------------------------\n",
      "autoint: input_shape (None, 27, 16), output_shape (None, 432)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Fold 4 fitting over.\n",
      "Fold 4 scoring over.\n",
      "Save model to:dt_output/dt_20200830 185355_autoint_nets/autoint_nets-kfold-4.h5.\n",
      "\n",
      "Fold:5\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 446)\n",
      "---------------------------------------------------------\n",
      "nets: ['autoint_nets']\n",
      "---------------------------------------------------------\n",
      "autoint: input_shape (None, 27, 16), output_shape (None, 432)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Fold 5 fitting over.\n",
      "Fold 5 scoring over.\n",
      "Save model to:dt_output/dt_20200830 185355_autoint_nets/autoint_nets-kfold-5.h5.\n",
      "fit_cross_validation cost:744.2857992649078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-30 19:06:19,418] Trial 6 finished with value: 0.8492022098637648 and parameters: {'nets': ['autoint_nets'], 'output_dim': 16}. Best is trial 4 with value: 0.8564291541758227.\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'fm_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'cin_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['dcn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['pnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['autoint_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['afm_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['fgcnn_dnn_nets'] which is of type list.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cross validation\n",
      "2 class detected, {0, 1}, so inferred as a [binary classification] task\n",
      "Preparing features cost:0.1002511978149414\n",
      "Imputation cost:0.10588979721069336\n",
      "Categorical encoding cost:0.20358562469482422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretization cost:0.14633464813232422\n",
      "fit_transform cost:0.5674660205841064\n",
      "transform X_test\n",
      "transform_X cost:3.8565433025360107\n",
      "Iterators:KFold(n_splits=5, random_state=22, shuffle=True)\n",
      "Injected a callback [EarlyStopping]. monitor:val_auc, patience:3, mode:max\n",
      "\n",
      "Fold:1\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 311)\n",
      "---------------------------------------------------------\n",
      "nets: ['dcn_nets']\n",
      "---------------------------------------------------------\n",
      "dcn-widecross: input_shape (None, 311), output_shape (None, 311)\n",
      "dcn-dnn2: input_shape (None, 311), output_shape (None, 1)\n",
      "dcn: input_shape (None, 311), output_shape (None, 312)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Fold 1 fitting over.\n",
      "Fold 1 scoring over.\n",
      "Save model to:dt_output/dt_20200830 190619_dcn_nets/dcn_nets-kfold-1.h5.\n",
      "\n",
      "Fold:2\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 311)\n",
      "---------------------------------------------------------\n",
      "nets: ['dcn_nets']\n",
      "---------------------------------------------------------\n",
      "dcn-widecross: input_shape (None, 311), output_shape (None, 311)\n",
      "dcn-dnn2: input_shape (None, 311), output_shape (None, 1)\n",
      "dcn: input_shape (None, 311), output_shape (None, 312)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Fold 2 fitting over.\n",
      "Fold 2 scoring over.\n",
      "Save model to:dt_output/dt_20200830 190619_dcn_nets/dcn_nets-kfold-2.h5.\n",
      "\n",
      "Fold:3\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 311)\n",
      "---------------------------------------------------------\n",
      "nets: ['dcn_nets']\n",
      "---------------------------------------------------------\n",
      "dcn-widecross: input_shape (None, 311), output_shape (None, 311)\n",
      "dcn-dnn2: input_shape (None, 311), output_shape (None, 1)\n",
      "dcn: input_shape (None, 311), output_shape (None, 312)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Fold 3 fitting over.\n",
      "Fold 3 scoring over.\n",
      "Save model to:dt_output/dt_20200830 190619_dcn_nets/dcn_nets-kfold-3.h5.\n",
      "\n",
      "Fold:4\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 311)\n",
      "---------------------------------------------------------\n",
      "nets: ['dcn_nets']\n",
      "---------------------------------------------------------\n",
      "dcn-widecross: input_shape (None, 311), output_shape (None, 311)\n",
      "dcn-dnn2: input_shape (None, 311), output_shape (None, 1)\n",
      "dcn: input_shape (None, 311), output_shape (None, 312)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Fold 4 fitting over.\n",
      "Fold 4 scoring over.\n",
      "Save model to:dt_output/dt_20200830 190619_dcn_nets/dcn_nets-kfold-4.h5.\n",
      "\n",
      "Fold:5\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 311)\n",
      "---------------------------------------------------------\n",
      "nets: ['dcn_nets']\n",
      "---------------------------------------------------------\n",
      "dcn-widecross: input_shape (None, 311), output_shape (None, 311)\n",
      "dcn-dnn2: input_shape (None, 311), output_shape (None, 1)\n",
      "dcn: input_shape (None, 311), output_shape (None, 312)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Fold 5 fitting over.\n",
      "Fold 5 scoring over.\n",
      "Save model to:dt_output/dt_20200830 190619_dcn_nets/dcn_nets-kfold-5.h5.\n",
      "fit_cross_validation cost:823.6891033649445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-30 19:20:03,130] Trial 7 finished with value: 0.8521241711172877 and parameters: {'nets': ['dcn_nets'], 'output_dim': 11}. Best is trial 4 with value: 0.8564291541758227.\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'fm_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'cin_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['dcn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['pnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['autoint_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['afm_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['fgcnn_dnn_nets'] which is of type list.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cross validation\n",
      "2 class detected, {0, 1}, so inferred as a [binary classification] task\n",
      "Preparing features cost:0.09682607650756836\n",
      "Imputation cost:0.10565686225891113\n",
      "Categorical encoding cost:0.20592474937438965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretization cost:0.1453232765197754\n",
      "fit_transform cost:0.5652875900268555\n",
      "transform X_test\n",
      "transform_X cost:3.885453939437866\n",
      "Iterators:KFold(n_splits=5, random_state=22, shuffle=True)\n",
      "Injected a callback [EarlyStopping]. monitor:val_auc, patience:3, mode:max\n",
      "\n",
      "Fold:1\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 203)\n",
      "---------------------------------------------------------\n",
      "nets: ['pnn_nets']\n",
      "---------------------------------------------------------\n",
      "pnn-inner_product: input_shape list(27), output_shape (None, 351)\n",
      "pnn-outer_product: input_shape list(27), output_shape (None, 351)\n",
      "pnn-dnn: input_shape (None, 905), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Fold 1 fitting over.\n",
      "Fold 1 scoring over.\n",
      "Save model to:dt_output/dt_20200830 192003_pnn_nets/pnn_nets-kfold-1.h5.\n",
      "\n",
      "Fold:2\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 203)\n",
      "---------------------------------------------------------\n",
      "nets: ['pnn_nets']\n",
      "---------------------------------------------------------\n",
      "pnn-inner_product: input_shape list(27), output_shape (None, 351)\n",
      "pnn-outer_product: input_shape list(27), output_shape (None, 351)\n",
      "pnn-dnn: input_shape (None, 905), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Fold 2 fitting over.\n",
      "Fold 2 scoring over.\n",
      "Save model to:dt_output/dt_20200830 192003_pnn_nets/pnn_nets-kfold-2.h5.\n",
      "\n",
      "Fold:3\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 203)\n",
      "---------------------------------------------------------\n",
      "nets: ['pnn_nets']\n",
      "---------------------------------------------------------\n",
      "pnn-inner_product: input_shape list(27), output_shape (None, 351)\n",
      "pnn-outer_product: input_shape list(27), output_shape (None, 351)\n",
      "pnn-dnn: input_shape (None, 905), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Fold 3 fitting over.\n",
      "Fold 3 scoring over.\n",
      "Save model to:dt_output/dt_20200830 192003_pnn_nets/pnn_nets-kfold-3.h5.\n",
      "\n",
      "Fold:4\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 203)\n",
      "---------------------------------------------------------\n",
      "nets: ['pnn_nets']\n",
      "---------------------------------------------------------\n",
      "pnn-inner_product: input_shape list(27), output_shape (None, 351)\n",
      "pnn-outer_product: input_shape list(27), output_shape (None, 351)\n",
      "pnn-dnn: input_shape (None, 905), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Fold 4 fitting over.\n",
      "Fold 4 scoring over.\n",
      "Save model to:dt_output/dt_20200830 192003_pnn_nets/pnn_nets-kfold-4.h5.\n",
      "\n",
      "Fold:5\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 203)\n",
      "---------------------------------------------------------\n",
      "nets: ['pnn_nets']\n",
      "---------------------------------------------------------\n",
      "pnn-inner_product: input_shape list(27), output_shape (None, 351)\n",
      "pnn-outer_product: input_shape list(27), output_shape (None, 351)\n",
      "pnn-dnn: input_shape (None, 905), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Fold 5 fitting over.\n",
      "Fold 5 scoring over.\n",
      "Save model to:dt_output/dt_20200830 192003_pnn_nets/pnn_nets-kfold-5.h5.\n",
      "fit_cross_validation cost:1337.790896654129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-30 19:42:20,944] Trial 8 finished with value: 0.8422127280185399 and parameters: {'nets': ['pnn_nets'], 'output_dim': 7}. Best is trial 4 with value: 0.8564291541758227.\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'fm_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'cin_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['dcn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['pnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['autoint_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['afm_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['fgcnn_dnn_nets'] which is of type list.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cross validation\n",
      "2 class detected, {0, 1}, so inferred as a [binary classification] task\n",
      "Preparing features cost:0.1024932861328125\n",
      "Imputation cost:0.10337042808532715\n",
      "Categorical encoding cost:0.206573486328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretization cost:0.1484088897705078\n",
      "fit_transform cost:0.5735058784484863\n",
      "transform X_test\n",
      "transform_X cost:3.85809063911438\n",
      "Iterators:KFold(n_splits=5, random_state=22, shuffle=True)\n",
      "Injected a callback [EarlyStopping]. monitor:val_auc, patience:3, mode:max\n",
      "\n",
      "Fold:1\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 473)\n",
      "---------------------------------------------------------\n",
      "nets: ['fgcnn_dnn_nets']\n",
      "---------------------------------------------------------\n",
      "fg: input_shape (None, 27, 17), output_shape (None, 109, 17)\n",
      "fgcnn-ipnn: input_shape (None, 109, 17), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Fold 1 fitting over.\n",
      "Fold 1 scoring over.\n",
      "Save model to:dt_output/dt_20200830 194220_fgcnn_dnn_nets/fgcnn_dnn_nets-kfold-1.h5.\n",
      "\n",
      "Fold:2\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 473)\n",
      "---------------------------------------------------------\n",
      "nets: ['fgcnn_dnn_nets']\n",
      "---------------------------------------------------------\n",
      "fg: input_shape (None, 27, 17), output_shape (None, 109, 17)\n",
      "fgcnn-ipnn: input_shape (None, 109, 17), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Fold 2 fitting over.\n",
      "Fold 2 scoring over.\n",
      "Save model to:dt_output/dt_20200830 194220_fgcnn_dnn_nets/fgcnn_dnn_nets-kfold-2.h5.\n",
      "\n",
      "Fold:3\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 473)\n",
      "---------------------------------------------------------\n",
      "nets: ['fgcnn_dnn_nets']\n",
      "---------------------------------------------------------\n",
      "fg: input_shape (None, 27, 17), output_shape (None, 109, 17)\n",
      "fgcnn-ipnn: input_shape (None, 109, 17), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Fold 3 fitting over.\n",
      "Fold 3 scoring over.\n",
      "Save model to:dt_output/dt_20200830 194220_fgcnn_dnn_nets/fgcnn_dnn_nets-kfold-3.h5.\n",
      "\n",
      "Fold:4\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 473)\n",
      "---------------------------------------------------------\n",
      "nets: ['fgcnn_dnn_nets']\n",
      "---------------------------------------------------------\n",
      "fg: input_shape (None, 27, 17), output_shape (None, 109, 17)\n",
      "fgcnn-ipnn: input_shape (None, 109, 17), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Fold 4 fitting over.\n",
      "Fold 4 scoring over.\n",
      "Save model to:dt_output/dt_20200830 194220_fgcnn_dnn_nets/fgcnn_dnn_nets-kfold-4.h5.\n",
      "\n",
      "Fold:5\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 473)\n",
      "---------------------------------------------------------\n",
      "nets: ['fgcnn_dnn_nets']\n",
      "---------------------------------------------------------\n",
      "fg: input_shape (None, 27, 17), output_shape (None, 109, 17)\n",
      "fgcnn-ipnn: input_shape (None, 109, 17), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Fold 5 fitting over.\n",
      "Fold 5 scoring over.\n",
      "Save model to:dt_output/dt_20200830 194220_fgcnn_dnn_nets/fgcnn_dnn_nets-kfold-5.h5.\n",
      "fit_cross_validation cost:1152.341136932373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-30 20:01:33,312] Trial 9 finished with value: 0.835480509811376 and parameters: {'nets': ['fgcnn_dnn_nets'], 'output_dim': 17}. Best is trial 4 with value: 0.8564291541758227.\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'fm_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'cin_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['dcn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['pnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['autoint_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['afm_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['fgcnn_dnn_nets'] which is of type list.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cross validation\n",
      "2 class detected, {0, 1}, so inferred as a [binary classification] task\n",
      "Preparing features cost:0.0985102653503418\n",
      "Imputation cost:0.1115419864654541\n",
      "Categorical encoding cost:0.20178723335266113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretization cost:0.14659476280212402\n",
      "fit_transform cost:0.5701415538787842\n",
      "transform X_test\n",
      "transform_X cost:3.8585450649261475\n",
      "Iterators:KFold(n_splits=5, random_state=22, shuffle=True)\n",
      "Injected a callback [EarlyStopping]. monitor:val_auc, patience:3, mode:max\n",
      "\n",
      "Fold:1\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 311)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 11), output_shape (None, 1)\n",
      "dnn: input_shape (None, 311), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Fold 1 fitting over.\n",
      "Fold 1 scoring over.\n",
      "Save model to:dt_output/dt_20200830 200133_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-1.h5.\n",
      "\n",
      "Fold:2\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 311)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 11), output_shape (None, 1)\n",
      "dnn: input_shape (None, 311), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Fold 2 fitting over.\n",
      "Fold 2 scoring over.\n",
      "Save model to:dt_output/dt_20200830 200133_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-2.h5.\n",
      "\n",
      "Fold:3\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 311)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 11), output_shape (None, 1)\n",
      "dnn: input_shape (None, 311), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Fold 3 fitting over.\n",
      "Fold 3 scoring over.\n",
      "Save model to:dt_output/dt_20200830 200133_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-3.h5.\n",
      "\n",
      "Fold:4\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 311)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 11), output_shape (None, 1)\n",
      "dnn: input_shape (None, 311), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00005: early stopping\n",
      "Fold 4 fitting over.\n",
      "Fold 4 scoring over.\n",
      "Save model to:dt_output/dt_20200830 200133_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-4.h5.\n",
      "\n",
      "Fold:5\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 311)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 11), output_shape (None, 1)\n",
      "dnn: input_shape (None, 311), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Fold 5 fitting over.\n",
      "Fold 5 scoring over.\n",
      "Save model to:dt_output/dt_20200830 200133_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-5.h5.\n",
      "fit_cross_validation cost:910.3944087028503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-30 20:16:43,735] Trial 10 finished with value: 0.8580325942816188 and parameters: {'nets': ['linear', 'cin_nets', 'dnn_nets'], 'output_dim': 11}. Best is trial 10 with value: 0.8580325942816188.\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'fm_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'cin_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['dcn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['pnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['autoint_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['afm_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['fgcnn_dnn_nets'] which is of type list.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cross validation\n",
      "2 class detected, {0, 1}, so inferred as a [binary classification] task\n",
      "Preparing features cost:0.10125994682312012\n",
      "Imputation cost:0.1043546199798584\n",
      "Categorical encoding cost:0.2059006690979004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretization cost:0.14613938331604004\n",
      "fit_transform cost:0.5693464279174805\n",
      "transform X_test\n",
      "transform_X cost:3.862978219985962\n",
      "Iterators:KFold(n_splits=5, random_state=22, shuffle=True)\n",
      "Injected a callback [EarlyStopping]. monitor:val_auc, patience:3, mode:max\n",
      "\n",
      "Fold:1\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 311)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 11), output_shape (None, 1)\n",
      "dnn: input_shape (None, 311), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Fold 1 fitting over.\n",
      "Fold 1 scoring over.\n",
      "Save model to:dt_output/dt_20200830 201643_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-1.h5.\n",
      "\n",
      "Fold:2\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 311)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 11), output_shape (None, 1)\n",
      "dnn: input_shape (None, 311), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Fold 2 fitting over.\n",
      "Fold 2 scoring over.\n",
      "Save model to:dt_output/dt_20200830 201643_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-2.h5.\n",
      "\n",
      "Fold:3\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 311)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 11), output_shape (None, 1)\n",
      "dnn: input_shape (None, 311), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00005: early stopping\n",
      "Fold 3 fitting over.\n",
      "Fold 3 scoring over.\n",
      "Save model to:dt_output/dt_20200830 201643_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-3.h5.\n",
      "\n",
      "Fold:4\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 311)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 11), output_shape (None, 1)\n",
      "dnn: input_shape (None, 311), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Fold 4 fitting over.\n",
      "Fold 4 scoring over.\n",
      "Save model to:dt_output/dt_20200830 201643_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-4.h5.\n",
      "\n",
      "Fold:5\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 311)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 11), output_shape (None, 1)\n",
      "dnn: input_shape (None, 311), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Fold 5 fitting over.\n",
      "Fold 5 scoring over.\n",
      "Save model to:dt_output/dt_20200830 201643_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-5.h5.\n",
      "fit_cross_validation cost:789.1186635494232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-30 20:29:52,883] Trial 11 finished with value: 0.8574326945873413 and parameters: {'nets': ['linear', 'cin_nets', 'dnn_nets'], 'output_dim': 11}. Best is trial 10 with value: 0.8580325942816188.\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'fm_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'cin_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['dcn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['pnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['autoint_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['afm_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['fgcnn_dnn_nets'] which is of type list.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cross validation\n",
      "2 class detected, {0, 1}, so inferred as a [binary classification] task\n",
      "Preparing features cost:0.09976935386657715\n",
      "Imputation cost:0.10421395301818848\n",
      "Categorical encoding cost:0.20395922660827637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretization cost:0.14679789543151855\n",
      "fit_transform cost:0.5665431022644043\n",
      "transform X_test\n",
      "transform_X cost:3.892547607421875\n",
      "Iterators:KFold(n_splits=5, random_state=22, shuffle=True)\n",
      "Injected a callback [EarlyStopping]. monitor:val_auc, patience:3, mode:max\n",
      "\n",
      "Fold:1\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 338)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 12), output_shape (None, 1)\n",
      "dnn: input_shape (None, 338), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Fold 1 fitting over.\n",
      "Fold 1 scoring over.\n",
      "Save model to:dt_output/dt_20200830 202952_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-1.h5.\n",
      "\n",
      "Fold:2\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 338)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 12), output_shape (None, 1)\n",
      "dnn: input_shape (None, 338), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Fold 2 fitting over.\n",
      "Fold 2 scoring over.\n",
      "Save model to:dt_output/dt_20200830 202952_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-2.h5.\n",
      "\n",
      "Fold:3\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 338)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 12), output_shape (None, 1)\n",
      "dnn: input_shape (None, 338), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Fold 3 fitting over.\n",
      "Fold 3 scoring over.\n",
      "Save model to:dt_output/dt_20200830 202952_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-3.h5.\n",
      "\n",
      "Fold:4\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 338)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 12), output_shape (None, 1)\n",
      "dnn: input_shape (None, 338), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Fold 4 fitting over.\n",
      "Fold 4 scoring over.\n",
      "Save model to:dt_output/dt_20200830 202952_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-4.h5.\n",
      "\n",
      "Fold:5\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 338)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 12), output_shape (None, 1)\n",
      "dnn: input_shape (None, 338), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Fold 5 fitting over.\n",
      "Fold 5 scoring over.\n",
      "Save model to:dt_output/dt_20200830 202952_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-5.h5.\n",
      "fit_cross_validation cost:929.352386713028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-30 20:45:22,264] Trial 12 finished with value: 0.8554534396207149 and parameters: {'nets': ['linear', 'cin_nets', 'dnn_nets'], 'output_dim': 12}. Best is trial 10 with value: 0.8580325942816188.\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'fm_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'cin_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['dcn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['pnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['autoint_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['afm_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['fgcnn_dnn_nets'] which is of type list.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cross validation\n",
      "2 class detected, {0, 1}, so inferred as a [binary classification] task\n",
      "Preparing features cost:0.09855794906616211\n",
      "Imputation cost:0.10797405242919922\n",
      "Categorical encoding cost:0.20105338096618652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretization cost:0.14638042449951172\n",
      "fit_transform cost:0.5653946399688721\n",
      "transform X_test\n",
      "transform_X cost:3.875136375427246\n",
      "Iterators:KFold(n_splits=5, random_state=22, shuffle=True)\n",
      "Injected a callback [EarlyStopping]. monitor:val_auc, patience:3, mode:max\n",
      "\n",
      "Fold:1\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 392)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "dnn: input_shape (None, 392), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Fold 1 fitting over.\n",
      "Fold 1 scoring over.\n",
      "Save model to:dt_output/dt_20200830 204522_linear_dnn_nets/linear_dnn_nets-kfold-1.h5.\n",
      "\n",
      "Fold:2\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 392)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "dnn: input_shape (None, 392), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Fold 2 fitting over.\n",
      "Fold 2 scoring over.\n",
      "Save model to:dt_output/dt_20200830 204522_linear_dnn_nets/linear_dnn_nets-kfold-2.h5.\n",
      "\n",
      "Fold:3\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 392)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "dnn: input_shape (None, 392), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Fold 3 fitting over.\n",
      "Fold 3 scoring over.\n",
      "Save model to:dt_output/dt_20200830 204522_linear_dnn_nets/linear_dnn_nets-kfold-3.h5.\n",
      "\n",
      "Fold:4\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 392)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "dnn: input_shape (None, 392), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Fold 4 fitting over.\n",
      "Fold 4 scoring over.\n",
      "Save model to:dt_output/dt_20200830 204522_linear_dnn_nets/linear_dnn_nets-kfold-4.h5.\n",
      "\n",
      "Fold:5\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 392)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "dnn: input_shape (None, 392), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Fold 5 fitting over.\n",
      "Fold 5 scoring over.\n",
      "Save model to:dt_output/dt_20200830 204522_linear_dnn_nets/linear_dnn_nets-kfold-5.h5.\n",
      "fit_cross_validation cost:936.1613395214081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-30 21:00:58,456] Trial 13 finished with value: 0.8509746136478844 and parameters: {'nets': ['linear', 'dnn_nets'], 'output_dim': 14}. Best is trial 10 with value: 0.8580325942816188.\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'fm_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'cin_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['dcn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['pnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['autoint_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['afm_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['fgcnn_dnn_nets'] which is of type list.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cross validation\n",
      "2 class detected, {0, 1}, so inferred as a [binary classification] task\n",
      "Preparing features cost:0.10199689865112305\n",
      "Imputation cost:0.10603570938110352\n",
      "Categorical encoding cost:0.20682191848754883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretization cost:0.14684772491455078\n",
      "fit_transform cost:0.5739469528198242\n",
      "transform X_test\n",
      "transform_X cost:3.896711826324463\n",
      "Iterators:KFold(n_splits=5, random_state=22, shuffle=True)\n",
      "Injected a callback [EarlyStopping]. monitor:val_auc, patience:3, mode:max\n",
      "\n",
      "Fold:1\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 284)\n",
      "---------------------------------------------------------\n",
      "nets: ['afm_nets']\n",
      "---------------------------------------------------------\n",
      "afm: input_shape list(27), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00004: early stopping\n",
      "Fold 1 fitting over.\n",
      "Fold 1 scoring over.\n",
      "Save model to:dt_output/dt_20200830 210058_afm_nets/afm_nets-kfold-1.h5.\n",
      "\n",
      "Fold:2\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 284)\n",
      "---------------------------------------------------------\n",
      "nets: ['afm_nets']\n",
      "---------------------------------------------------------\n",
      "afm: input_shape list(27), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00004: early stopping\n",
      "Fold 2 fitting over.\n",
      "Fold 2 scoring over.\n",
      "Save model to:dt_output/dt_20200830 210058_afm_nets/afm_nets-kfold-2.h5.\n",
      "\n",
      "Fold:3\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 284)\n",
      "---------------------------------------------------------\n",
      "nets: ['afm_nets']\n",
      "---------------------------------------------------------\n",
      "afm: input_shape list(27), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00004: early stopping\n",
      "Fold 3 fitting over.\n",
      "Fold 3 scoring over.\n",
      "Save model to:dt_output/dt_20200830 210058_afm_nets/afm_nets-kfold-3.h5.\n",
      "\n",
      "Fold:4\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 284)\n",
      "---------------------------------------------------------\n",
      "nets: ['afm_nets']\n",
      "---------------------------------------------------------\n",
      "afm: input_shape list(27), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00004: early stopping\n",
      "Fold 4 fitting over.\n",
      "Fold 4 scoring over.\n",
      "Save model to:dt_output/dt_20200830 210058_afm_nets/afm_nets-kfold-4.h5.\n",
      "\n",
      "Fold:5\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 284)\n",
      "---------------------------------------------------------\n",
      "nets: ['afm_nets']\n",
      "---------------------------------------------------------\n",
      "afm: input_shape list(27), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00004: early stopping\n",
      "Fold 5 fitting over.\n",
      "Fold 5 scoring over.\n",
      "Save model to:dt_output/dt_20200830 210058_afm_nets/afm_nets-kfold-5.h5.\n",
      "fit_cross_validation cost:320.74168944358826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-30 21:06:19,224] Trial 14 finished with value: 0.5007189056807874 and parameters: {'nets': ['afm_nets'], 'output_dim': 10}. Best is trial 10 with value: 0.8580325942816188.\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'fm_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'cin_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['dcn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['pnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['autoint_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['afm_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['fgcnn_dnn_nets'] which is of type list.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cross validation\n",
      "2 class detected, {0, 1}, so inferred as a [binary classification] task\n",
      "Preparing features cost:0.0987999439239502\n",
      "Imputation cost:0.10357284545898438\n",
      "Categorical encoding cost:0.20549678802490234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretization cost:0.14693164825439453\n",
      "fit_transform cost:0.5662448406219482\n",
      "transform X_test\n",
      "transform_X cost:3.9098613262176514\n",
      "Iterators:KFold(n_splits=5, random_state=22, shuffle=True)\n",
      "Injected a callback [EarlyStopping]. monitor:val_auc, patience:3, mode:max\n",
      "\n",
      "Fold:1\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 527)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 19), output_shape (None, 1)\n",
      "dnn: input_shape (None, 527), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Fold 1 fitting over.\n",
      "Fold 1 scoring over.\n",
      "Save model to:dt_output/dt_20200830 210619_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-1.h5.\n",
      "\n",
      "Fold:2\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 527)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 19), output_shape (None, 1)\n",
      "dnn: input_shape (None, 527), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Fold 2 fitting over.\n",
      "Fold 2 scoring over.\n",
      "Save model to:dt_output/dt_20200830 210619_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-2.h5.\n",
      "\n",
      "Fold:3\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 527)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 19), output_shape (None, 1)\n",
      "dnn: input_shape (None, 527), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Fold 3 fitting over.\n",
      "Fold 3 scoring over.\n",
      "Save model to:dt_output/dt_20200830 210619_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-3.h5.\n",
      "\n",
      "Fold:4\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 527)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 19), output_shape (None, 1)\n",
      "dnn: input_shape (None, 527), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Fold 4 fitting over.\n",
      "Fold 4 scoring over.\n",
      "Save model to:dt_output/dt_20200830 210619_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-4.h5.\n",
      "\n",
      "Fold:5\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 527)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 19), output_shape (None, 1)\n",
      "dnn: input_shape (None, 527), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Fold 5 fitting over.\n",
      "Fold 5 scoring over.\n",
      "Save model to:dt_output/dt_20200830 210619_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-5.h5.\n",
      "fit_cross_validation cost:992.4272236824036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-30 21:22:51,680] Trial 15 finished with value: 0.8532530463107141 and parameters: {'nets': ['linear', 'cin_nets', 'dnn_nets'], 'output_dim': 19}. Best is trial 10 with value: 0.8580325942816188.\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'fm_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'cin_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['dcn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['pnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['autoint_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['afm_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['fgcnn_dnn_nets'] which is of type list.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cross validation\n",
      "2 class detected, {0, 1}, so inferred as a [binary classification] task\n",
      "Preparing features cost:0.10114288330078125\n",
      "Imputation cost:0.10334968566894531\n",
      "Categorical encoding cost:0.20470619201660156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretization cost:0.14577984809875488\n",
      "fit_transform cost:0.5669870376586914\n",
      "transform X_test\n",
      "transform_X cost:3.8996243476867676\n",
      "Iterators:KFold(n_splits=5, random_state=22, shuffle=True)\n",
      "Injected a callback [EarlyStopping]. monitor:val_auc, patience:3, mode:max\n",
      "\n",
      "Fold:1\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 392)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 14), output_shape (None, 1)\n",
      "dnn: input_shape (None, 392), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Fold 1 fitting over.\n",
      "Fold 1 scoring over.\n",
      "Save model to:dt_output/dt_20200830 212251_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-1.h5.\n",
      "\n",
      "Fold:2\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 392)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 14), output_shape (None, 1)\n",
      "dnn: input_shape (None, 392), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Fold 2 fitting over.\n",
      "Fold 2 scoring over.\n",
      "Save model to:dt_output/dt_20200830 212251_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-2.h5.\n",
      "\n",
      "Fold:3\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 392)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 14), output_shape (None, 1)\n",
      "dnn: input_shape (None, 392), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Fold 3 fitting over.\n",
      "Fold 3 scoring over.\n",
      "Save model to:dt_output/dt_20200830 212251_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-3.h5.\n",
      "\n",
      "Fold:4\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 392)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 14), output_shape (None, 1)\n",
      "dnn: input_shape (None, 392), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Fold 4 fitting over.\n",
      "Fold 4 scoring over.\n",
      "Save model to:dt_output/dt_20200830 212251_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-4.h5.\n",
      "\n",
      "Fold:5\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 392)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 14), output_shape (None, 1)\n",
      "dnn: input_shape (None, 392), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Fold 5 fitting over.\n",
      "Fold 5 scoring over.\n",
      "Save model to:dt_output/dt_20200830 212251_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-5.h5.\n",
      "fit_cross_validation cost:1111.037333726883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-30 21:41:22,746] Trial 16 finished with value: 0.8549652696930891 and parameters: {'nets': ['linear', 'cin_nets', 'dnn_nets'], 'output_dim': 14}. Best is trial 10 with value: 0.8580325942816188.\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'fm_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'cin_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['dcn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['pnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['autoint_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['afm_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['fgcnn_dnn_nets'] which is of type list.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cross validation\n",
      "2 class detected, {0, 1}, so inferred as a [binary classification] task\n",
      "Preparing features cost:0.10124611854553223\n",
      "Imputation cost:0.10157418251037598\n",
      "Categorical encoding cost:0.20540904998779297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretization cost:0.14686965942382812\n",
      "fit_transform cost:0.5671863555908203\n",
      "transform X_test\n",
      "transform_X cost:3.8739125728607178\n",
      "Iterators:KFold(n_splits=5, random_state=22, shuffle=True)\n",
      "Injected a callback [EarlyStopping]. monitor:val_auc, patience:3, mode:max\n",
      "\n",
      "Fold:1\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 149)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 5), output_shape (None, 1)\n",
      "dnn: input_shape (None, 149), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Fold 1 fitting over.\n",
      "Fold 1 scoring over.\n",
      "Save model to:dt_output/dt_20200830 214122_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-1.h5.\n",
      "\n",
      "Fold:2\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 149)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 5), output_shape (None, 1)\n",
      "dnn: input_shape (None, 149), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Fold 2 fitting over.\n",
      "Fold 2 scoring over.\n",
      "Save model to:dt_output/dt_20200830 214122_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-2.h5.\n",
      "\n",
      "Fold:3\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 149)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 5), output_shape (None, 1)\n",
      "dnn: input_shape (None, 149), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Fold 3 fitting over.\n",
      "Fold 3 scoring over.\n",
      "Save model to:dt_output/dt_20200830 214122_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-3.h5.\n",
      "\n",
      "Fold:4\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 149)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 5), output_shape (None, 1)\n",
      "dnn: input_shape (None, 149), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Fold 4 fitting over.\n",
      "Fold 4 scoring over.\n",
      "Save model to:dt_output/dt_20200830 214122_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-4.h5.\n",
      "\n",
      "Fold:5\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 149)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "cin: input_shape (None, 27, 5), output_shape (None, 1)\n",
      "dnn: input_shape (None, 149), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Fold 5 fitting over.\n",
      "Fold 5 scoring over.\n",
      "Save model to:dt_output/dt_20200830 214122_linear_cin_nets_dnn_nets/linear_cin_nets_dnn_nets-kfold-5.h5.\n",
      "fit_cross_validation cost:976.0775239467621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-30 21:57:38,852] Trial 17 finished with value: 0.8521038109656272 and parameters: {'nets': ['linear', 'cin_nets', 'dnn_nets'], 'output_dim': 5}. Best is trial 10 with value: 0.8580325942816188.\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'fm_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'cin_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['dcn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['pnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['autoint_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['afm_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['fgcnn_dnn_nets'] which is of type list.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cross validation\n",
      "2 class detected, {0, 1}, so inferred as a [binary classification] task\n",
      "Preparing features cost:0.09887886047363281\n",
      "Imputation cost:0.10358595848083496\n",
      "Categorical encoding cost:0.2060108184814453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretization cost:0.14628314971923828\n",
      "fit_transform cost:0.5662491321563721\n",
      "transform X_test\n",
      "transform_X cost:3.8594932556152344\n",
      "Iterators:KFold(n_splits=5, random_state=22, shuffle=True)\n",
      "Injected a callback [EarlyStopping]. monitor:val_auc, patience:3, mode:max\n",
      "\n",
      "Fold:1\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 365)\n",
      "---------------------------------------------------------\n",
      "nets: ['afm_nets']\n",
      "---------------------------------------------------------\n",
      "afm: input_shape list(27), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00004: early stopping\n",
      "Fold 1 fitting over.\n",
      "Fold 1 scoring over.\n",
      "Save model to:dt_output/dt_20200830 215738_afm_nets/afm_nets-kfold-1.h5.\n",
      "\n",
      "Fold:2\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 365)\n",
      "---------------------------------------------------------\n",
      "nets: ['afm_nets']\n",
      "---------------------------------------------------------\n",
      "afm: input_shape list(27), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00004: early stopping\n",
      "Fold 2 fitting over.\n",
      "Fold 2 scoring over.\n",
      "Save model to:dt_output/dt_20200830 215738_afm_nets/afm_nets-kfold-2.h5.\n",
      "\n",
      "Fold:3\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 365)\n",
      "---------------------------------------------------------\n",
      "nets: ['afm_nets']\n",
      "---------------------------------------------------------\n",
      "afm: input_shape list(27), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00004: early stopping\n",
      "Fold 3 fitting over.\n",
      "Fold 3 scoring over.\n",
      "Save model to:dt_output/dt_20200830 215738_afm_nets/afm_nets-kfold-3.h5.\n",
      "\n",
      "Fold:4\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 365)\n",
      "---------------------------------------------------------\n",
      "nets: ['afm_nets']\n",
      "---------------------------------------------------------\n",
      "afm: input_shape list(27), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00004: early stopping\n",
      "Fold 4 fitting over.\n",
      "Fold 4 scoring over.\n",
      "Save model to:dt_output/dt_20200830 215738_afm_nets/afm_nets-kfold-4.h5.\n",
      "\n",
      "Fold:5\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 365)\n",
      "---------------------------------------------------------\n",
      "nets: ['afm_nets']\n",
      "---------------------------------------------------------\n",
      "afm: input_shape list(27), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00004: early stopping\n",
      "Fold 5 fitting over.\n",
      "Fold 5 scoring over.\n",
      "Save model to:dt_output/dt_20200830 215738_afm_nets/afm_nets-kfold-5.h5.\n",
      "fit_cross_validation cost:312.2373580932617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-30 22:02:51,117] Trial 18 finished with value: 0.5062647495040044 and parameters: {'nets': ['afm_nets'], 'output_dim': 13}. Best is trial 10 with value: 0.8580325942816188.\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'fm_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'cin_nets', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['dcn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['pnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['linear', 'dnn_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['autoint_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['afm_nets'] which is of type list.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/optuna/distributions.py:406: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['fgcnn_dnn_nets'] which is of type list.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cross validation\n",
      "2 class detected, {0, 1}, so inferred as a [binary classification] task\n",
      "Preparing features cost:0.09831857681274414\n",
      "Imputation cost:0.10794830322265625\n",
      "Categorical encoding cost:0.20405149459838867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n",
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning:\n",
      "\n",
      "Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretization cost:0.14636015892028809\n",
      "fit_transform cost:0.568493127822876\n",
      "transform X_test\n",
      "transform_X cost:4.25767183303833\n",
      "Iterators:KFold(n_splits=5, random_state=22, shuffle=True)\n",
      "Injected a callback [EarlyStopping]. monitor:val_auc, patience:3, mode:max\n",
      "\n",
      "Fold:1\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 284)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "dnn: input_shape (None, 284), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/deeptable/.venv/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Fold 1 fitting over.\n",
      "Fold 1 scoring over.\n",
      "Save model to:dt_output/dt_20200830 220251_linear_dnn_nets/linear_dnn_nets-kfold-1.h5.\n",
      "\n",
      "Fold:2\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 284)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "dnn: input_shape (None, 284), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Fold 2 fitting over.\n",
      "Fold 2 scoring over.\n",
      "Save model to:dt_output/dt_20200830 220251_linear_dnn_nets/linear_dnn_nets-kfold-2.h5.\n",
      "\n",
      "Fold:3\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 284)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "dnn: input_shape (None, 284), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Fold 3 fitting over.\n",
      "Fold 3 scoring over.\n",
      "Save model to:dt_output/dt_20200830 220251_linear_dnn_nets/linear_dnn_nets-kfold-3.h5.\n",
      "\n",
      "Fold:4\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 284)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "dnn: input_shape (None, 284), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Fold 4 fitting over.\n",
      "Fold 4 scoring over.\n",
      "Save model to:dt_output/dt_20200830 220251_linear_dnn_nets/linear_dnn_nets-kfold-4.h5.\n",
      "\n",
      "Fold:5\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (27)', 'input_continuous_all: (14)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [44, 13, 5, 6, 4, 4, 5, 32, 14, 142, 7, 6, 6, 6, 5, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 3, 3]\n",
      "output_dims: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "dropout: 0.0\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 284)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 41), output_shape (None, 1)\n",
      "dnn: input_shape (None, 284), output_shape (None, 1)\n",
      "---------------------------------------------------------\n",
      "stacking_op: concat\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Fold 5 fitting over.\n",
      "Fold 5 scoring over.\n",
      "Save model to:dt_output/dt_20200830 220251_linear_dnn_nets/linear_dnn_nets-kfold-5.h5.\n",
      "fit_cross_validation cost:799.6982433795929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-30 22:16:10,844] Trial 19 finished with value: 0.8447847201505206 and parameters: {'nets': ['linear', 'dnn_nets'], 'output_dim': 10}. Best is trial 10 with value: 0.8580325942816188.\n"
     ]
    }
   ],
   "source": [
    "objective = Objective()\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20, callbacks=[objective.callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 20\n",
      "Best trial:\n",
      "  Value: 0.8580325942816188\n",
      "  Params: \n",
      "    nets: ['linear', 'cin_nets', 'dnn_nets']\n",
      "    output_dim: 11\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('nets', 0.9758862268961521),\n",
       "             ('output_dim', 0.02411377310384796)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optuna.importance.get_param_importances(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79820156, 0.115652  , 0.03500745, ..., 0.05878278, 0.00248398,\n",
       "       0.13792531], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective.best_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df[1] = objective.best_pred\n",
    "submit_df.to_csv('submit-dt.csv', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeptables",
   "language": "python",
   "name": "deeptables"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
